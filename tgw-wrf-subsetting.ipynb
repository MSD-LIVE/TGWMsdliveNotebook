{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d56afa-bc63-4f1a-8502-a6f38e1d3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cartopy.crs as ccrs # just for plotting\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt # just for plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pygris import counties, states\n",
    "import xarray as xr # also need to install netcdf4 and dask[complete]\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad7bdc-6f1b-44c6-b9a7-fd74e4c4646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset of counties and states for subsetting\n",
    "\n",
    "# CONUS states\n",
    "conus_states = states(cb=True, year=2020, cache=True).to_crs(\"epsg:4326\")\n",
    "conus_states = conus_states[~conus_states.NAME.isin([\n",
    "    'Alaska','American Samoa','Puerto Rico','United States Virgin Islands',\n",
    "    'Hawaii','Guam','Commonwealth of the Northern Mariana Islands',\n",
    "])]\n",
    "\n",
    "# CONUS counties\n",
    "conus_counties = counties(cb=True, year=2020, cache=True).to_crs(\"epsg:4326\")\n",
    "conus_counties = conus_counties[conus_counties.STATEFP.isin(\n",
    "    conus_states.STATEFP\n",
    ")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ceec38-5227-408d-97c0-80f28ead0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to fix the weird WRF indexing\n",
    "# and load the time/space dimensions into memory\n",
    "def preprocess(d):\n",
    "    d = d.rename_dims({\n",
    "        'Time': 'time',\n",
    "    }).rename_vars({\n",
    "        'XLAT': 'lat',\n",
    "        'XLONG': 'lon',\n",
    "    })\n",
    "    d['time'] = pd.to_datetime(\n",
    "        d.Times.load().astype(str).str.replace('_', ' ')\n",
    "    )\n",
    "    d = d.drop_vars(['Times'])\n",
    "    d['lat'] = d.lat.isel(time=0).load()\n",
    "    d['lon'] = d.lon.isel(time=0).load()\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc7ad7-b119-460c-94ae-313130e2bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgw_subset(\n",
    "    *,\n",
    "    start: str, # 'YYYY-MM-DD' or 'YYYY-MM-DDTHH:MM:SS'\n",
    "    end: str, # 'YYYY-MM-DD' or 'YYYY-MM-DDTHH:MM:SS'\n",
    "    county_fips: str = None, # county FIPS code to keep, None for all\n",
    "    state_abbreviation: str = None, # State abbreviation to keep, None for all\n",
    "    min_lat: float = None, # minimum latitude in WGS84 (epsg:4326)\n",
    "    max_lat: float = None, # maximum latitude in WGS84 (epsg:4326)\n",
    "    min_lon: float = None, # minimum longitude in WGS84 (epsg:4326)\n",
    "    max_lon: float = None, # maximum longitude in WGS84 (epsg:4326)\n",
    "    variables = None, # list of variables to keep, None for all\n",
    "    data_glob = './data/*.nc', # glob to all the data files\n",
    "    load = True, # if True, load the data before returning; otherwise return the chunked dask dataset\n",
    "    write_to_file = False, # if a path, write subset to that path; if False don't\n",
    "):\n",
    "\n",
    "    # NOTE that certain variables (precipitation, etc) are presented as \"cumulative\",\n",
    "    #      meaning that the user may actually need one timestep before the requested\n",
    "    #      start time in order to fully resolve those variables\n",
    "    # TODO this is not accounted for in this method\n",
    "\n",
    "    # NOTE that the WRF data presented in WGS84 (epsg:4326) projection as is the case\n",
    "    #      here is NOT on a rectilinear grid, which can be confusing to work with, but\n",
    "    #      the native WRF projection IS on a rectilinear grid but those coordinates are\n",
    "    #      not provided by default (see the python package salem for more details...)\n",
    "\n",
    "    # NOTE the data_glob must be used to filter by scenario,\n",
    "    #      but users may benefit from a wrapper for that functionality too\n",
    "\n",
    "    # collect and sort paths to all the files\n",
    "    # assumes the sorting by filename correctly orders files by time\n",
    "    all_files = sorted(glob(data_glob))\n",
    "\n",
    "    # subset to the necessary years of data\n",
    "    # doesn't account for requested years not found in the data\n",
    "    # one could make this more sophisticated for higher efficiency\n",
    "    # i.e. by dealing with months and weeks too\n",
    "    # assumes filenames unambiguously have years in them...\n",
    "    start_year = int(start[:4])\n",
    "    end_year = int(end[:4])\n",
    "    years = list(np.arange(start_year, end_year+1))\n",
    "    year_files = [p for p in all_files if any(str(y) in p for y in years)]\n",
    "\n",
    "    # open the files with dask chunks\n",
    "    # TODO may be more efficient chunking method than the default...\n",
    "    d = xr.open_mfdataset(year_files, parallel=True, preprocess=preprocess)\n",
    "\n",
    "    # subset by variables\n",
    "    # TODO may help to ignore or just warn about requested variables that don't\n",
    "    #      exist, rather than just fail\n",
    "    if variables is not None:\n",
    "        d = d[variables]\n",
    "    \n",
    "    # subset by date\n",
    "    d = d.sel(time=slice(start, end))\n",
    "\n",
    "    # subset by space\n",
    "    # NOTE that there could be errors caused by use of -180 to 180 vs 0 to 360 nomenclature\n",
    "    # TODO may want to build in a buffer to be sure to catch the edges of the shape\n",
    "    if (state_abbreviation is not None):\n",
    "        state_bounds = conus_states[conus_states.STUSPS == state_abbreviation.upper()].bounds.iloc[0]\n",
    "        d = d.where(\n",
    "            (d.lat>=state_bounds.miny) &\n",
    "            (d.lat<=state_bounds.maxy) &\n",
    "            (d.lon>=state_bounds.minx) &\n",
    "            (d.lon<=state_bounds.maxx),\n",
    "            drop=True,\n",
    "        )\n",
    "    if (county_fips is not None):\n",
    "        county_bounds = conus_counties[conus_counties.GEOID == county_fips].bounds.iloc[0]\n",
    "        d = d.where(\n",
    "            (d.lat>=county_bounds.miny) &\n",
    "            (d.lat<=county_bounds.maxy) &\n",
    "            (d.lon>=county_bounds.minx) &\n",
    "            (d.lon<=county_bounds.maxx),\n",
    "            drop=True,\n",
    "        )\n",
    "    if (min_lat is not None) or (max_lat is not None) or (min_lon is not None) or (max_lon is not None):\n",
    "        d = d.where(\n",
    "            (d.lat>=(min_lat if min_lat is not None else -np.Inf)) &\n",
    "            (d.lat<=(max_lat if max_lat is not None else np.Inf)) &\n",
    "            (d.lon>=(min_lon if min_lon is not None else -np.Inf)) &\n",
    "            (d.lon<=(max_lon if max_lon is not None else np.Inf)),\n",
    "            drop=True,\n",
    "        )\n",
    "\n",
    "    # write the data to file if requested\n",
    "    if write_to_file:\n",
    "        d.to_netcdf(write_to_file)\n",
    "\n",
    "    # loading the data fully into memory takes some time\n",
    "    # a user skilled with dask may benefit from keeping the data unloaded\n",
    "    # until the end of their data transformations\n",
    "    if load:\n",
    "        return d.load()\n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a41682-234e-4c50-b13d-44dcfc7dcd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ea810-8b50-4d76-9976-6e641fa45317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "HOME = os.environ.get("HOME")\n",
    "DATA_DIR = os.path.join(HOME, "data/s3")\n",
    "d = get_tgw_subset(\n",
    "    start='2088-01-01',\n",
    "    end='2088-02-01T00:00:00',\n",
    "    variables=['T2'],\n",
    "    # county_fips='53033',\n",
    "    state_abbreviation='wa',\n",
    "    # min_lat=45.543830,\n",
    "    # max_lat=49.002405,\n",
    "    # min_lon=-124.7336,\n",
    "    # max_lon=-116.9161,\n",
    "    data_glob='./data/*.nc',\n",
    "    load=False,\n",
    "    write_to_file='./subset.nc',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ee56c-13c4-41d6-af00-ea0426800907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the subset\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc66f2-5177-4b02-bea0-4c19aeb2c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the subset in the usual WGS84 datum\n",
    "fig = plt.figure(figsize=(10.8, 7.2), dpi=150, layout='tight')\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(), frameon=False)\n",
    "conus_counties[conus_counties.STUSPS == 'WA'].boundary.plot(ax=ax, transform=ccrs.PlateCarree(), linewidth=0.5, color='black')\n",
    "d.isel(time=0).T2.plot(ax=ax, transform=ccrs.PlateCarree(), x=\"lon\", y=\"lat\", alpha=0.5, cmap='coolwarm')\n",
    "ax.set_title('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74c228-4341-441b-bf22-bd5060eb9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the subset in the TGW-WRF native projection\n",
    "# '+proj=lcc +lat_0=40.0000076293945 +lon_0=-97 +lat_1=30 +lat_2=45 +x_0=0 +y_0=0 +R=6370000 +units=m +no_defs'\n",
    "tgw_crs = ccrs.LambertConformal(\n",
    "    central_longitude=-97.0,\n",
    "    central_latitude=40.0000076293945,\n",
    "    standard_parallels=(30, 45),\n",
    "    globe=None,\n",
    ")\n",
    "fig = plt.figure(figsize=(10.8, 7.2), dpi=150, layout='tight')\n",
    "ax = plt.axes(projection=tgw_crs, frameon=False)\n",
    "conus_counties[conus_counties.STUSPS == 'WA'].boundary.plot(ax=ax, transform=ccrs.PlateCarree(), linewidth=0.5, color='black')\n",
    "d.isel(time=0).T2.plot(ax=ax, transform=ccrs.PlateCarree(), x=\"lon\", y=\"lat\", alpha=0.5, cmap='coolwarm')\n",
    "ax.set_title('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765748be-b740-4199-89f4-61ae91bd062c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc361145-2541-4d00-814d-8fd7c7645267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msdtgw",
   "language": "python",
   "name": "msdtgw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
